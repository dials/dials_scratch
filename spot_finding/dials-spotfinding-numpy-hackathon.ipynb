{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hdf5plugin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-815a7d8a5fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhdf5plugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hdf5plugin'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "import h5py\n",
    "import hdf5plugin\n",
    "import numba\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import skimage.transform.integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"/dls/science/groups/scisoft/DIALS/dials_data/vmxi_thaumatin/image_15799.nxs\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = f[\"/entry/data/data\"][0]\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_valid = 65534\n",
    "mask = (image <= max_valid).astype(image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(image, norm=colors.SymLogNorm(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 7\n",
    "kernel = np.ones((kernel_size, kernel_size))\n",
    "kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive approach using `scipy.ndimage.convolve`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "masked_image = image * mask\n",
    "im = masked_image.astype(np.float)\n",
    "im2 = im**2\n",
    "sum_image = ndimage.convolve(im, kernel, mode=\"constant\", cval=0)\n",
    "sum_sq = ndimage.convolve(im2, kernel, mode=\"constant\", cval=0)\n",
    "n = ndimage.convolve(mask.astype(int), kernel, mode=\"constant\", cval=0)\n",
    "mean_image = np.zeros(im.shape)\n",
    "np.divide(sum_image, n, where=(n > 0), out=mean_image)\n",
    "inv_count = np.zeros(im.shape)\n",
    "np.divide(1, n, where=(n > 0), out=inv_count)\n",
    "variance_image = (sum_sq - inv_count * sum_image ** 2) * inv_count\n",
    "dispersion_index = np.ones(mean_image.shape)\n",
    "np.divide(variance_image, mean_image, where=(mean_image > 0), out=dispersion_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(mean_image, norm=colors.SymLogNorm(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(variance_image, norm=colors.SymLogNorm(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(dispersion_index, norm=colors.SymLogNorm(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `np.cumsum` to calculate the summed area tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summed_area_table(image):\n",
    "    sat = np.empty(image.shape, dtype=image.dtype)\n",
    "    image.cumsum(axis=0, out=sat)\n",
    "    sat.cumsum(axis=1, out=sat)\n",
    "    return sat\n",
    "\n",
    "def kernel_sum(image, kernel_size):\n",
    "    pad = (kernel_size-1)//2\n",
    "    image = np.pad(image, (pad+1, pad))\n",
    "    sat = summed_area_table(image)\n",
    "    #sat = skimage.transform.integral.integral_image(image)\n",
    "    return (\n",
    "        sat[:-kernel_size,:-kernel_size] + # top left\n",
    "        sat[kernel_size:,kernel_size:] - # bottom right\n",
    "        sat[kernel_size:,:-kernel_size] - # top right\n",
    "        sat[:-kernel_size,kernel_size:] # bottom left\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "masked_image = image * mask\n",
    "im = masked_image\n",
    "im2 = im**2\n",
    "\n",
    "sum_image = kernel_sum(masked_image, kernel_size)\n",
    "sum_sq = kernel_sum(im2, kernel_size)\n",
    "n = kernel_sum(mask, kernel_size)\n",
    "mean_image = np.zeros(im.shape)\n",
    "np.divide(sum_image, n, where=(n > 0), out=mean_image)\n",
    "inv_count = np.zeros(im.shape)\n",
    "np.divide(1, n, where=(n > 0), out=inv_count)\n",
    "variance_image = (sum_sq - inv_count * np.square(sum_image)) * inv_count\n",
    "dispersion_index = np.ones(mean_image.shape)\n",
    "np.divide(variance_image, mean_image, where=(mean_image > 0), out=dispersion_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `numba` to calculate the summed area tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(numba.int32[:,::1](numba.int32[:,::1]))\n",
    "def summed_area_table(image):\n",
    "    sat = np.zeros(image.shape, dtype=image.dtype)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            sat[i, j] = image[i, j] + sat[i, j - 1] + sat[i - 1, j] - sat[i - 1, j - 1]\n",
    "    return sat\n",
    "\n",
    "\n",
    "def kernel_sum(image, kernel_size):\n",
    "    pad = (kernel_size-1)//2\n",
    "    image = np.pad(image, (pad+1, pad))\n",
    "    sat = summed_area_table(image)\n",
    "    return (\n",
    "        sat[:-kernel_size,:-kernel_size] + # top left\n",
    "        sat[kernel_size:,kernel_size:] - # bottom right\n",
    "        sat[kernel_size:,:-kernel_size] - # top right\n",
    "        sat[:-kernel_size,kernel_size:] # bottom left\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating out computation of the variance made an appreciable difference over using `np.divide`. Note how numba handles division by zero (see `error_model` in https://numba.pydata.org/numba-doc/dev/reference/jit-compilation.html?highlight=error_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(error_model=\"python\")\n",
    "def compute_variance(sum_image, sum_image_sq, n):\n",
    "    return (sum_image_sq - np.square(sum_image) / n) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "masked_image = image * mask\n",
    "im = masked_image\n",
    "im2 = im**2\n",
    "\n",
    "sum_image = kernel_sum(masked_image, kernel_size)\n",
    "sum_sq = kernel_sum(im2, kernel_size)\n",
    "n = kernel_sum(mask, kernel_size)\n",
    "mean_image = np.zeros(im.shape)\n",
    "np.divide(sum_image, n, where=(n > 0), out=mean_image)\n",
    "variance_image = compute_variance(sum_image, sum_sq, n)\n",
    "dispersion_index = np.ones(mean_image.shape)\n",
    "np.divide(variance_image, mean_image, where=(mean_image > 0), out=dispersion_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(dispersion_index, norm=colors.SymLogNorm(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried calculating the three summed area tables simultaneously (as in the dials source code), but this didn't seem to make any measurable difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
